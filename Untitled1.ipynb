{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2792e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 360 nodes and 21149 edges\n",
      "Degree distribution: (array([35, 54, 33, 25, 19, 31, 46, 35, 51, 31]), array([  0. ,  23.3,  46.6,  69.9,  93.2, 116.5, 139.8, 163.1, 186.4,\n",
      "       209.7, 233. ]))\n",
      "Edge weight distribution: (array([9781, 6177, 3068, 1350,  453,  187,   89,   30,    9,    5]), array([0.50000711, 0.65439939, 0.80879167, 0.96318395, 1.11757624,\n",
      "       1.27196852, 1.4263608 , 1.58075309, 1.73514537, 1.88953765,\n",
      "       2.04392993]))\n",
      "Computed metrics: {'degree_centrality': 0.3272825750541628, 'betweenness_centrality': 0.002245573174674807, 'eigenvector_centrality': 0.043338489078057936, 'clustering_coefficient': 0.6923418382241122, 'modularity': 0.13464466364658595, 'connected_components': 2}\n",
      "degree_centrality: 0.3272825750541628\n",
      "betweenness_centrality: 0.002245573174674807\n",
      "eigenvector_centrality: 0.043338489078057936\n",
      "clustering_coefficient: 0.6923418382241122\n",
      "modularity: 0.13464466364658595\n",
      "connected_components: 2\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# Function to load data\n",
    "def load_data(file_path):\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    key = [k for k in mat.keys() if not k.startswith('__')][0]\n",
    "    matrix = mat[key]\n",
    "    return matrix\n",
    "\n",
    "# Function to compute graph metrics\n",
    "def compute_graph_metrics(G):\n",
    "    try:\n",
    "        degree_centrality = np.mean([val for val in nx.degree_centrality(G).values()])\n",
    "        betweenness_centrality = np.mean([val for val in nx.betweenness_centrality(G).values()])\n",
    "        eigenvector_centrality = np.mean([val for val in nx.eigenvector_centrality(G).values()])\n",
    "        clustering_coefficient = nx.average_clustering(G)\n",
    "        \n",
    "        communities = list(nx.community.greedy_modularity_communities(G))\n",
    "        modularity = nx.algorithms.community.quality.modularity(G, communities) if communities else np.nan\n",
    "        \n",
    "        connected_components = nx.number_connected_components(G)\n",
    "        \n",
    "        return {\n",
    "            'degree_centrality': degree_centrality,\n",
    "            'betweenness_centrality': betweenness_centrality,\n",
    "            'eigenvector_centrality': eigenvector_centrality,\n",
    "            'clustering_coefficient': clustering_coefficient,\n",
    "            'modularity': modularity,\n",
    "            'connected_components': connected_components\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing metrics: {e}\")\n",
    "        return {\n",
    "            'degree_centrality': None,\n",
    "            'betweenness_centrality': None,\n",
    "            'eigenvector_centrality': None,\n",
    "            'clustering_coefficient': None,\n",
    "            'modularity': None,\n",
    "            'connected_components': None\n",
    "        }\n",
    "\n",
    "# Load data for specific files\n",
    "file_path = '/Users/shenxiaoyu/Desktop/Brain data/shamzfc_s1.mat'\n",
    "matrix = load_data(file_path)\n",
    "adj_matrix = matrix[0]\n",
    "\n",
    "# Check for self-loops and remove them\n",
    "np.fill_diagonal(adj_matrix, 0)\n",
    "\n",
    "# Set negative weights to zero\n",
    "adj_matrix[adj_matrix < 0] = 0\n",
    "\n",
    "# Apply a threshold to the adjacency matrix to remove weak connections\n",
    "threshold = 0.5  # This can be adjusted based on your data\n",
    "adj_matrix[adj_matrix < threshold] = 0\n",
    "\n",
    "# Convert to NetworkX graph\n",
    "G = nx.from_numpy_matrix(adj_matrix)\n",
    "\n",
    "# Print basic info about the graph for debugging\n",
    "print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "\n",
    "# Visualize degree distribution for debugging\n",
    "degrees = [degree for _, degree in G.degree()]\n",
    "degree_hist = np.histogram(degrees)\n",
    "print(f\"Degree distribution: {degree_hist}\")\n",
    "\n",
    "# Check edge weight distribution for debugging\n",
    "weights = [d['weight'] for (u, v, d) in G.edges(data=True)]\n",
    "weight_hist = np.histogram(weights)\n",
    "print(f\"Edge weight distribution: {weight_hist}\")\n",
    "\n",
    "# Compute and print metrics for debugging\n",
    "metrics = compute_graph_metrics(G)\n",
    "print(\"Computed metrics:\", metrics)\n",
    "\n",
    "# Print detailed metrics for debugging\n",
    "for metric, value in metrics.items():\n",
    "    if value is None or np.isnan(value):\n",
    "        print(f\"{metric} is None or NaN\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a7830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
