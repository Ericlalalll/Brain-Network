{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0b3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "from scipy.stats import ttest_rel, ttest_ind\n",
    "import time   #预估运行时间(可删除)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e2c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 储存文件路径\n",
    "folder_path = '/Users/shenxiaoyu/Desktop/FC'\n",
    "\n",
    "file_paths = [\n",
    "    'shamfc_s1.mat', 'shamfc_s2.mat', 'shamfc_s3.mat',\n",
    "    'tacs6fc_s1.mat', 'tacs6fc_s2.mat', 'tacs6fc_s3.mat',\n",
    "    'tacs10fc_s1.mat', 'tacs10fc_s2.mat', 'tacs10fc_s3.mat',\n",
    "    'tdcsfc_s1.mat', 'tdcsfc_s2.mat', 'tdcsfc_s3.mat'\n",
    "]\n",
    "\n",
    "\n",
    "# preprocessing brain data\n",
    "def data_preprocessing(matrix, fc_threshold=0.25, zfc_threshold=1.5):\n",
    "    # matrix = np.where(np.isinf(matrix), np.nan, matrix)  # Replace infinite values with NaN\n",
    "    \n",
    "    # Apply threshold to create a binary adjacency matrix\n",
    "    threshold = zfc_threshold if 'zfc' in file_path.lower() else fc_threshold\n",
    "    binary_weighted_matrix = np.where(np.abs(matrix) >= threshold, matrix, 0)\n",
    "    \n",
    "    # Remove self-loops\n",
    "    np.fill_diagonal(binary_weighted_matrix, 0)\n",
    "    \n",
    "    return binary_weighted_matrix\n",
    "\n",
    "# 创建一个dict来存储每种条件下的graph\n",
    "graphs = {\n",
    "    'sham': {'s1': [], 's2': [], 's3': []},\n",
    "    'tacs6': {'s1': [], 's2': [], 's3': []},\n",
    "    'tacs10': {'s1': [], 's2': [], 's3': []},\n",
    "    'tdcs': {'s1': [], 's2': [], 's3': []}\n",
    "}\n",
    "\n",
    "# 读取文件里的matrix和提取ZFC\n",
    "for file_name in file_paths:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    key = [k for k in mat.keys() if not k.startswith('__')][0]  # 提取主要数据的key\n",
    "    matrix = mat[key]\n",
    "    \n",
    "    # condition是刺激类型, time_point对应刺激前中后\n",
    "    base_name = file_name.replace('.mat', '')\n",
    "    parts = base_name.split('_')\n",
    "    if len(parts) == 2:\n",
    "        condition_time, time_point = parts\n",
    "        if 'zfc' in condition_time:\n",
    "            condition = condition_time.replace('zfc', '')\n",
    "            matrix_type = 'zfc'\n",
    "        else:\n",
    "            condition = condition_time.replace('fc', '')\n",
    "            matrix_type = 'fc'\n",
    "    else:\n",
    "        condition, matrix_type, time_point = parts\n",
    "\n",
    "    \n",
    "    if matrix_type == 'fc':\n",
    "        # 将其转换为graph\n",
    "        for i in range(matrix.shape[0]):\n",
    "            adj_matrix_binary = data_preprocessing(matrix[i])\n",
    "            G = nx.from_numpy_matrix(adj_matrix_binary)\n",
    "            graphs[condition][time_point].append(G)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d983570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WhitakerLab. (n.d.). Scona: Structural Covariance Networks. Retrieved [date], from https://whitakerlab.github.io/scona/_modules/scona/graph_measures.html\n",
    "def participation_coefficient(G, module_partition):\n",
    "    \"\"\" Calculate the participation coefficient for each node in the graph. \"\"\"\n",
    "    pc_dict = {}\n",
    "    for m in module_partition.keys():\n",
    "        M = set(module_partition[m])\n",
    "        for v in M:\n",
    "            degree = float(nx.degree(G=G, nbunch=v))\n",
    "            wm_degree = float(sum([1 for u in M if (u, v) in G.edges()]))\n",
    "            pc_dict[v] = 1 - ((float(wm_degree) / float(degree)) ** 2)\n",
    "    return pc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e5f7b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx.algorithms.community.quality' has no attribute 'participation_coefficient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5h/x_p7ky7d4ts4dz4c7g75h28c0000gn/T/ipykernel_20916/966477556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_graph_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5h/x_p7ky7d4ts4dz4c7g75h28c0000gn/T/ipykernel_20916/966477556.py\u001b[0m in \u001b[0;36mcompute_graph_metrics\u001b[0;34m(G, existing_metrics)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'participation_coefficient_new'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy_modularity_communities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participation_coefficient_new'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticipation_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'connected_components'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'connected_components'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_connected_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx.algorithms.community.quality' has no attribute 'participation_coefficient'"
     ]
    }
   ],
   "source": [
    "# 定义所需要计算的graph property\n",
    "def compute_graph_metrics(G):\n",
    "    return {\n",
    "        'degree_centrality': np.mean(list(nx.degree_centrality(G).values())),\n",
    "        'betweenness_centrality': np.mean(list(nx.betweenness_centrality(G, weight='weight').values())),\n",
    "        'eigenvector_centrality': np.mean(list(nx.eigenvector_centrality(G, max_iter=10000, weight='weight').values())),\n",
    "        'clustering_coefficient': nx.average_clustering(G, weight='weight'),\n",
    "        'modularity': nx.algorithms.community.quality.modularity(G, nx.community.greedy_modularity_communities(G, weight='weight'), weight='weight'),\n",
    "        'connected_components': nx.number_connected_components(G),\n",
    "        'minimum_spanning_tree': nx.minimum_spanning_tree(G, weight='weight', ignore_nan=True).size(weight='weight') if nx.is_connected(G) else None\n",
    "        'rich_club_coefficient': \n",
    "\n",
    "    }\n",
    "\n",
    "# 创建一个dict来储存计算结果\n",
    "metrics = {\n",
    "    'sham': {'s1': [], 's2': [], 's3': []},\n",
    "    'tacs6': {'s1': [], 's2': [], 's3': []},\n",
    "    'tacs10': {'s1': [], 's2': [], 's3': []},\n",
    "    'tdcs': {'s1': [], 's2': [], 's3': []}\n",
    "}\n",
    "\n",
    "# 预估运行时间(可删除)\n",
    "metrics_start_time = time.time()\n",
    "total_graphs = sum(len(graphs[condition][time_point]) for condition in graphs for time_point in graphs[condition])\n",
    "processed_graphs = 0\n",
    "\n",
    "for condition in graphs:\n",
    "    for time_point in graphs[condition]:\n",
    "        for G in graphs[condition][time_point]:\n",
    "            metrics[condition][time_point].append(compute_graph_metrics(G))\n",
    "            \n",
    "            \n",
    "            # 预估运行时间(可删除)\n",
    "            processed_graphs += 1\n",
    "            elapsed_time = time.time() - metrics_start_time\n",
    "            estimated_total_time = (elapsed_time / processed_graphs) * total_graphs\n",
    "            remaining_time = estimated_total_time - elapsed_time\n",
    "            print(f\"Processed {processed_graphs}/{total_graphs} graphs. Estimated remaining time: {remaining_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_analysis(metrics, condition1, time_point1, condition2, time_point2, graph_property, paired=False):\n",
    "    data1 = [m[graph_property] for m in metrics[condition1][time_point1] if m[graph_property] is not None]\n",
    "    data2 = [m[graph_property] for m in metrics[condition2][time_point2] if m[graph_property] is not None]\n",
    "    if len(data1) > 0 and len(data2) > 0:\n",
    "        if paired:\n",
    "            t_stat, p_value = ttest_rel(data1, data2)\n",
    "        else:\n",
    "            t_stat, p_value = ttest_ind(data1, data2)\n",
    "    else:\n",
    "        t_stat, p_value = None, None\n",
    "    return t_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 比较sham组在s1,s2,s3的差异 (期待没有显著差异)\n",
    "\"\"\"print(\"Sham Group Stability:\")\n",
    "for graph_property in ['degree_centrality', 'betweenness_centrality', 'eigenvector_centrality', 'clustering_coefficient', 'modularity', 'rich_club_coefficient_new', 'connected_components', 'minimum_spanning_tree']:\n",
    "    t_stat, p_value = compare_analysis(metrics, 'sham', 's1', 'sham', 's2', graph_property, paired=True)\n",
    "    print(f\"Sham S1 vs S2 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "    \n",
    "    t_stat, p_value = compare_analysis(metrics, 'sham', 's1', 'sham', 's3', graph_property, paired=True)\n",
    "    print(f\"Sham S1 vs S3 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5db23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 验证四组s1相似性 (期待四组s1没有显著差异)\n",
    "print(\"S_1:\")\n",
    "for condition in ['tacs6', 'tacs10', 'tdcs']:\n",
    "    for graph_property in ['degree_centrality', 'betweenness_centrality', 'eigenvector_centrality', 'clustering_coefficient', 'modularity', 'rich_club_coefficient_new', 'participation_coefficient_new', 'connected_components', 'minimum_spanning_tree']:\n",
    "        t_stat, p_value = compare_analysis(metrics, 'sham', 's1', condition, 's1', graph_property)\n",
    "        print(f\"Sham S1 vs {condition} S1 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 验证真实刺激的s2,s3与sham组的对比\n",
    "print(\"S_2:\")\n",
    "for condition in ['tacs6', 'tacs10', 'tdcs']:\n",
    "    for graph_property in ['degree_centrality', 'betweenness_centrality', 'eigenvector_centrality', 'clustering_coefficient', 'modularity', 'rich_club_coefficient_new', 'participation_coefficient_new', 'connected_components', 'minimum_spanning_tree']:\n",
    "        # 比较 s2\n",
    "        t_stat, p_value = compare_analysis(metrics, 'sham', 's2', condition, 's2', graph_property)\n",
    "        print(f\"{condition} S2 vs Sham S2 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"S_3:\")\n",
    "for condition in ['tacs6', 'tacs10', 'tdcs']:\n",
    "    for graph_property in ['degree_centrality', 'betweenness_centrality', 'eigenvector_centrality', 'clustering_coefficient', 'modularity', 'rich_club_coefficient_new', 'participation_coefficient_new', 'connected_components', 'minimum_spanning_tree']:        \n",
    "        # 比较 s3\n",
    "        t_stat, p_value = compare_analysis(metrics, 'sham', 's3', condition, 's3', graph_property)\n",
    "        print(f\"{condition} S3 vs Sham S3 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 比较真实刺激组在s1,s2,s3的差异\n",
    "\"\"\"print(\"Real Stimulation Self Comparison:\")\n",
    "for condition in ['tacs6', 'tacs10', 'tdcs']:\n",
    "    for graph_property in ['degree_centrality', 'betweenness_centrality', 'eigenvector_centrality', 'clustering_coefficient', 'modularity', 'connected_components', 'minimum_spanning_tree']:\n",
    "        # 比较 s1 和 s2\n",
    "        t_stat, p_value = compare_analysis(metrics, condition, 's1', condition, 's2', graph_property, paired=True)\n",
    "        print(f\"{condition} S1 vs S2 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "        \n",
    "        # 比较 s1 和 s3\n",
    "        t_stat, p_value = compare_analysis(metrics, condition, 's1', condition, 's3', graph_property, paired=True)\n",
    "        print(f\"{condition} S1 vs S3 - {graph_property}: T-statistic: {t_stat}, P-value: {p_value}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53450174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
